{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  MSSV : 18110014 - Họ tên : Nguyễn Phú Thành\n",
    "# Bài thực hành Nhập môn máy học - Lab 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationMetric:\n",
    "    def __init__(self, y_truth, y_predict, positive_label = 1, negative_label = 0):\n",
    "        # True positive\n",
    "        self.TP = ((y_truth == positive_label) & (y_predict == positive_label)).astype(np.uint8).sum()\n",
    "        # True negative\n",
    "        self.TN = ((y_truth == negative_label) & (y_predict == negative_label)).astype(np.uint8).sum()\n",
    "        # False positive\n",
    "        self.FP = ((y_truth == negative_label) & (y_predict == positive_label)).astype(np.uint8).sum()\n",
    "        # False negative\n",
    "        self.FN = ((y_truth == positive_label) & (y_predict == negative_label)).astype(np.uint8).sum()\n",
    "    \n",
    "    def precision_score(self):\n",
    "        return (self.TP)/(self.TP + self.FP)\n",
    "    \n",
    "    def recall_score(self):\n",
    "        return (self.TP)/(self.TP + self.FN)\n",
    "    \n",
    "    def accuracy_score(self):\n",
    "        return (self.TP + self.TN)/(self.TP + self.TN + self.FP + self.FN)\n",
    "    \n",
    "    def f1_score(self):\n",
    "        precision = self.precision_score()\n",
    "        recall = self.recall_score()\n",
    "        return 2 * precision * recall/(precision + recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Hãy xây dựng mô hình logistic regression bằng tất cả các features trong file heart, so sánh với thư viện sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticReg:\n",
    "    @staticmethod\n",
    "    def getBatches(X, y, batch_size = 10):\n",
    "        sample_size = X.shape[0]\n",
    "\n",
    "        for i in range(0, sample_size, batch_size):\n",
    "            batch_X, batch_y = X[i:(i+batch_size), :], y[i:(i+batch_size)]\n",
    "            yield batch_X, batch_y\n",
    "\n",
    "    @classmethod\n",
    "    def gradient_loss(cls, theta, X, y, lmbda = 0):\n",
    "        h_theta = 1/(1 + np.exp(-X.dot(theta)))\n",
    "        number_sample, dimension = X.shape[:2]\n",
    "\n",
    "        regularization_term = np.zeros((dimension, 1))\n",
    "\n",
    "        regularization_term[1:] = 2 * theta[1:]\n",
    "\n",
    "        gradient = 1/number_sample * X.T.dot(h_theta - y) + lmbda * regularization_term\n",
    "\n",
    "        return gradient\n",
    "\n",
    "    def __init__(self, nb_epoch, batch_size = None, learning_rate = 1e-3, lmbda = 0):\n",
    "        '''\n",
    "            LogisticReg's constructor\n",
    "            ------------------------------\n",
    "            Parameters:\n",
    "                nb_epoch: int\n",
    "                    Number of epoches\n",
    "                batch_size: int, default None\n",
    "                    If batch_size is None then perform Batch Gradient Descent\n",
    "                    If batch_size == 1 then perform Stochastic Gradient Descent\n",
    "                    If batch_size > 1 then perform Mini Batch Gradient Descent\n",
    "                learning_rate: float, default 1e-3\n",
    "        '''\n",
    "        self.epoch, self.batch_size, self.rate = nb_epoch, batch_size, learning_rate\n",
    "\n",
    "        # Define loss's gradient\n",
    "\n",
    "        self.gradient = lambda theta, batch_X, batch_y: LogisticReg.gradient_loss(theta, batch_X, batch_y, lmbda)\n",
    "\n",
    "        self.theta = None\n",
    "\n",
    "    def fit(self, X, y, init_theta = None, random_state = 0):\n",
    "        '''\n",
    "            Fit linear model\n",
    "            ----------------------------\n",
    "            Parameters:\n",
    "                X: np.ndarray of shape (sample_size, dimension)\n",
    "                    Training data\n",
    "                y: np.ndarray of shape (sample_size, 1)\n",
    "                    Target values\n",
    "                init_theta: np.ndarray of shape (dimension, 1), default None\n",
    "                    Initial value for theta\n",
    "                    If None, initial value for theta will be chosen by normal distribution N(0, 1)\n",
    "                random_state: int, default 0\n",
    "                    Random state to set initial theta and to shuffle data for each epoch\n",
    "            ----------------------------\n",
    "            Returns: LogisticReg's instance\n",
    "        '''\n",
    "        rnd = np.random.RandomState(random_state)\n",
    "        X = X.copy()\n",
    "        y = y.reshape((y.shape[0], 1))\n",
    "        sample_size, dimension = X.shape[:2]\n",
    "\n",
    "        if init_theta is None:\n",
    "            self.theta = rnd.normal(loc = 0, scale = 1, size = dimension).reshape((dimension, 1))\n",
    "        else:\n",
    "            self.theta = init_theta.copy()\n",
    "\n",
    "        # If it is BGD (batch_size = None) then not shuffle else shuffle dataset\n",
    "        shuffle = True\n",
    "        if self.batch_size == None:\n",
    "            self.batch_size = sample_size\n",
    "            shuffle = False\n",
    "\n",
    "        for i in range(self.epoch):\n",
    "            if shuffle:\n",
    "                # Stack X and y horizontally\n",
    "                data = np.hstack((X, y))\n",
    "                # Shuffle inplace\n",
    "                rnd.shuffle(data)\n",
    "                # Get back X, y after shuffle\n",
    "                X, y = data[:, :dimension], data[:, dimension:]\n",
    "\n",
    "            for batch_X, batch_y in LogisticReg.getBatches(X, y, batch_size = self.batch_size):\n",
    "                # Update theta\n",
    "                self.theta = self.theta - self.rate * self.gradient(self.theta, batch_X, batch_y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "            Predict using the linear model.\n",
    "            ---------------------\n",
    "            Parameters:\n",
    "                X: np.ndarray\n",
    "                    Samples\n",
    "            ---------------------\n",
    "            Returns: np.ndarray\n",
    "        '''\n",
    "\n",
    "        assert self.theta is not None, 'Model needs to fit to a training set before making prediction'\n",
    "\n",
    "        if len(X.shape) == 1: # Predict one sample\n",
    "            dimension, = X.shape\n",
    "            X = X.reshape((1, dimension))\n",
    "        predict_y = np.where(X.dot(self.theta) < 0, 0, 1)\n",
    "\n",
    "        return predict_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.iloc[:, :-1].to_numpy(), data.iloc[:, -1].to_numpy()\n",
    "y = y.reshape((y.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = X_train.mean(axis = 0).reshape((1, X_train.shape[1]))\n",
    "std = np.sqrt(np.cov(X_train, rowvar = False, ddof = 1).diagonal()).reshape((1, X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = (X_train - mean)/std\n",
    "X_test = (X_test - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.hstack(\n",
    "    (\n",
    "        np.ones((X_train.shape[0], 1)),\n",
    "        X_train\n",
    "    )\n",
    ")\n",
    "\n",
    "X_test = np.hstack(\n",
    "    (\n",
    "        np.ones((X_test.shape[0], 1)),\n",
    "        X_test\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticReg(\n",
    "    nb_epoch = 24200, batch_size = None, learning_rate = 0.01, lmbda = 0\n",
    ").fit(X_train, y_train, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_train = ClassificationMetric(y_train, clf.predict(X_train).flatten())\n",
    "metric_test = ClassificationMetric(y_test, clf.predict(X_test).flatten())\n",
    "\n",
    "summary_table = pd.DataFrame(\n",
    "    data = {\n",
    "        'Training dataset': (\n",
    "            metric_train.precision_score(),\n",
    "            metric_train.accuracy_score(),\n",
    "            metric_train.recall_score()\n",
    "        ),\n",
    "        'Testing dataset': (\n",
    "            metric_test.precision_score(),\n",
    "            metric_test.accuracy_score(),\n",
    "            metric_test.recall_score()\n",
    "        )\n",
    "    },\n",
    "    index = ('Precision score', 'Accuracy score', 'Recall score')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_sklearn = LogisticRegression(\n",
    "    penalty = 'none',\n",
    "    fit_intercept = False, \n",
    "    random_state = 0\n",
    ").fit(X_train, y_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_train = ClassificationMetric(y_train, clf_sklearn.predict(X_train))\n",
    "metric_test = ClassificationMetric(y_test, clf_sklearn.predict(X_test))\n",
    "\n",
    "summary_table_sklearn = pd.DataFrame(\n",
    "    data = {\n",
    "        'Training dataset': (\n",
    "            metric_train.precision_score(),\n",
    "            metric_train.accuracy_score(),\n",
    "            metric_train.recall_score()\n",
    "        ),\n",
    "        'Testing dataset': (\n",
    "            metric_test.precision_score(),\n",
    "            metric_test.accuracy_score(),\n",
    "            metric_test.recall_score()\n",
    "        )\n",
    "    },\n",
    "    index = ('Precision score', 'Accuracy score', 'Recall score')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training dataset</th>\n",
       "      <th>Testing dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision score</th>\n",
       "      <td>0.541322</td>\n",
       "      <td>0.557377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy score</th>\n",
       "      <td>0.506147</td>\n",
       "      <td>0.512228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall score</th>\n",
       "      <td>0.574380</td>\n",
       "      <td>0.606557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Training dataset  Testing dataset\n",
       "Precision score          0.541322         0.557377\n",
       "Accuracy score           0.506147         0.512228\n",
       "Recall score             0.574380         0.606557"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training dataset</th>\n",
       "      <th>Testing dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision score</th>\n",
       "      <td>0.541322</td>\n",
       "      <td>0.557377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy score</th>\n",
       "      <td>0.506147</td>\n",
       "      <td>0.512228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall score</th>\n",
       "      <td>0.574380</td>\n",
       "      <td>0.606557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Training dataset  Testing dataset\n",
       "Precision score          0.541322         0.557377\n",
       "Accuracy score           0.506147         0.512228\n",
       "Recall score             0.574380         0.606557"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_table_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11145947, -0.0688732 , -0.93543064,  0.85226323, -0.2031756 ,\n",
       "        -0.28236505, -0.15007363,  0.09670082,  0.53850469, -0.49377506,\n",
       "        -0.69283718,  0.12972914, -0.94151826, -0.48601289]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_sklearn.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.11148124, -0.06892789, -0.93543231,  0.85227392, -0.2031619 ,\n",
       "       -0.28234248, -0.15006828,  0.09668824,  0.53841091, -0.49378617,\n",
       "       -0.69281688,  0.12977992, -0.94151942, -0.4860068 ])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.theta.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hãy xây dựng mô hình softmax regression trên bộ Iris (nên Normalize data), so sánh với thư viện sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxReg:\n",
    "    @staticmethod\n",
    "    def getBatches(X, y, batch_size = 10):\n",
    "        sample_size = X.shape[0]\n",
    "\n",
    "        for i in range(0, sample_size, batch_size):\n",
    "            batch_X, batch_y = X[i:(i+batch_size), :], y[i:(i+batch_size)]\n",
    "            yield batch_X, batch_y\n",
    "    @classmethod\n",
    "    def gradient_loss(cls, theta, index, X, y):\n",
    "        number_sample, dimension = X.shape[:2]\n",
    "        \n",
    "        X_theta = X.dot(theta)\n",
    "        exponent = np.exp(X_theta)\n",
    "        softmax = exponent/exponent.sum(axis = 1).reshape((number_sample, 1))\n",
    "        softmax_index = softmax[:, index].reshape((number_sample, 1))\n",
    "\n",
    "        bool_y = (y == index).astype(np.int).reshape((number_sample, 1))\n",
    "        \n",
    "        gradient = 1/number_sample * ((-bool_y + softmax_index) * X).sum(axis = 0).reshape((dimension, 1))\n",
    "\n",
    "        return gradient\n",
    "    \n",
    "    def __init__(self, nb_epoch, nb_classes, batch_size = None, learning_rate = 1e-3):\n",
    "        self.epoch, self.classes, self.batch_size, self.rate = nb_epoch, nb_classes, batch_size, learning_rate\n",
    "        self.gradient = lambda theta, index, batch_X, batch_y: (\n",
    "            SoftmaxReg.gradient_loss(theta, index, batch_X, batch_y)\n",
    "        )\n",
    "        self.theta = None\n",
    "    \n",
    "    def fit(self, X, y, init_theta = None, random_state = 0):\n",
    "        rnd = np.random.RandomState(random_state)\n",
    "        X = X.copy()\n",
    "        y = y.reshape((y.shape[0], 1))\n",
    "        sample_size, dimension = X.shape[:2]\n",
    "        \n",
    "        if init_theta is None:\n",
    "            self.theta = (\n",
    "                rnd.normal(loc = 0, scale = 1, size = dimension * self.classes)\n",
    "                .reshape((dimension, self.classes))\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            self.theta = init_theta.copy()\n",
    "\n",
    "        # If it is BGD (batch_size = None) then not shuffle else shuffle dataset\n",
    "        shuffle = True\n",
    "        if self.batch_size == None:\n",
    "            self.batch_size = sample_size\n",
    "            shuffle = False\n",
    "        for i in range(self.epoch):\n",
    "            if shuffle:\n",
    "                # Stack X and y horizontally\n",
    "                data = np.hstack((X, y))\n",
    "                # Shuffle inplace\n",
    "                rnd.shuffle(data)\n",
    "                # Get back X, y after shuffle\n",
    "                X, y = data[:, :dimension], data[:, dimension:]\n",
    "\n",
    "            for batch_X, batch_y in LogisticReg.getBatches(X, y, batch_size = self.batch_size):\n",
    "                # Update theta\n",
    "                for j in range(self.classes):\n",
    "                    col_theta = self.theta[:, j].reshape((dimension, 1))\n",
    "                    col_theta = col_theta - self.rate * self.gradient(self.theta, j, batch_X, batch_y)\n",
    "                    self.theta[:, j] = col_theta.flatten()\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        assert self.theta is not None, 'Model needs to fit to a training set before making prediction'\n",
    "\n",
    "        if len(X.shape) == 1: # Predict one sample\n",
    "            dimension, = X.shape\n",
    "            X = X.reshape((1, dimension))\n",
    "        \n",
    "        number_sample, dimension = X.shape[:2]\n",
    "        X_theta = X.dot(self.theta)\n",
    "        exponent = np.exp(X_theta)\n",
    "        softmax = exponent/exponent.sum(axis = 1).reshape((number_sample, 1))\n",
    "        predict_y = softmax.argmax(axis = 1)\n",
    "\n",
    "        return predict_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = X_train.mean(axis = 0).reshape((1, X_train.shape[1]))\n",
    "std = np.sqrt(np.cov(X_train, rowvar = False, ddof = 1).diagonal()).reshape((1, X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - mean)/std\n",
    "X_test = (X_test - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.hstack(\n",
    "    (\n",
    "        np.ones((X_train.shape[0], 1)),\n",
    "        X_train\n",
    "    )\n",
    ")\n",
    "\n",
    "X_test = np.hstack(\n",
    "    (\n",
    "        np.ones((X_test.shape[0], 1)),\n",
    "        X_test\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SoftmaxReg(nb_epoch = 1000, nb_classes = 3, learning_rate = 0.1).fit(X_train, y_train, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_sklearn = LogisticRegression(\n",
    "    penalty = 'none',\n",
    "    max_iter = 1000,\n",
    "    fit_intercept = False,\n",
    "    random_state = 0\n",
    ").fit(X_train, y_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_test.flatten() == clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_sklearn.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
